term_frequency_df <- tibble(term = names(term_frequency), frequency = term_frequency)
term_frequency_df
print(term_frequency_df, n=100)
get_stem_mapping <- function(text) {
words <- unlist(strsplit(text, " "))
stemmed_words <- wordStem(words, language = "indonesian")
data.frame(original = words, stemmed = stemmed_words)
}
stem_mappings <- do.call(rbind, lapply(text, get_stem_mapping))
get_stem_mapping <- function(text) {
words <- unlist(strsplit(text, " "))
stemmed_words <- wordStem(words, language = "indonesian")
data.frame(original = words, stemmed = stemmed_words)
}
stem_mappings <- do.call(rbind, lapply(text, get_stem_mapping))
get_stem_mapping <- function(sentence) {
words <- unlist(strsplit(sentence, " "))
stemmed_words <- wordStem(words, language = "indonesian")
data.frame(original = words, stemmed = stemmed_words, stringsAsFactors = FALSE)
}
stem_mappings <- do.call(rbind, lapply(text, get_stem_mapping))
get_stem_mapping <- function(sentence) {
words <- unlist(strsplit(sentence, " "))
stemmed_words <- wordStem(words, language = "indonesian")
data.frame(original = words, stemmed = stemmed_words, stringsAsFactors = FALSE)
}
stem_mappings <- do.call(rbind, lapply(data$id, get_stem_mapping))
word_counts <- stem_mappings %>%
group_by(stemmed, original) %>%
summarise(frequency = n()) %>%
arrange(desc(frequency))
most_common_words <- word_counts %>%
group_by(stemmed) %>%
slice_max(frequency, n = 1) %>%
ungroup() %>%
arrange(desc(frequency))
print(most_common_words)
print(most_common_words, n=100)
print(most_common_words, n=300)
print(most_common_words, n=20) %>% clipr::write_clip()
print(most_common_words, n=20)
print(most_common_words, n=20) %>% clipr::write_clip()
stemmed	original	frequency
most_common_words %>% slice(n=20)
most_common_words %>% slice(20)
most_common_words %>% slice(1:20)
most_common_words %>% slice(1:20) %>% clipr::write_clip()
most_common_words %>% slice(21:100) %>% clipr::write_clip()
most_common_words %>% select(-1) %>% slice(101:300) %>% clipr::write_clip()
most_common_words %>% select(-1, -3) %>% slice(101:300) %>% clipr::write_clip()
most_common_words %>% slice(101:300) %>% clipr::write_clip()
most_common_words %>% slice(301:600) %>% clipr::write_clip()
most_common_words %>% select(-1,-3) %>% slice(301:600) %>% clipr::write_clip()
combine(1:6)
combine(1:6, 1:6)
expand_grid(1:6, 1:6)
expand_grid(first_die = 1:6, second_die = 1:6) %>% mutate(sum_dice = first_die + second_die)
expand_grid(first_die = 1:6, second_die = 1:6) %>% mutate(sum_dice = first_die + second_die, equals_six = sum_dice == 6)
expand_grid(first_die = 1:6, second_die = 1:6) %>% mutate(sum_dice = first_die + second_die, equals_six = sum_dice == 6) %>% summarize(sum(equals_six))
expand_grid(first_die = 1:6, second_die = 1:6) %>% mutate(sum_dice = first_die + second_die, equals_six = sum_dice == 6) %>% filter(equals_six == TRUE)
?set.seed()
?min
min(2, -6, 700, -1)
min(2, -6, 700, -10)
sample(1:100)
sample(1:100)
sample(1:100)
sample(1:100)
pmin(5:1, pi)
min(5:1, pi)
airquality
tibble(airquality)
tibble(mtcars)
dataset_names
tibble(iris)
hist(iris$Sepal.Length)
?iris
matplot(c(1, 8), c(0, 4.5), type =  "n", xlab = "Length", ylab = "Width",
main = "Petal and Sepal Dimensions in Iris Blossoms")
matpoints(iris[iS,c(1,3)], iris[iS,c(2,4)], pch = "sS", col = c(2,4))
table(iris$Species) # is data.frame with 'Species' factor
iS <- iris$Species == "setosa"
iV <- iris$Species == "versicolor"
op <- par(bg = "bisque")
matplot(c(1, 8), c(0, 4.5), type =  "n", xlab = "Length", ylab = "Width",
main = "Petal and Sepal Dimensions in Iris Blossoms")
matpoints(iris[iS,c(1,3)], iris[iS,c(2,4)], pch = "sS", col = c(2,4))
matpoints(iris[iV,c(1,3)], iris[iV,c(2,4)], pch = "vV", col = c(2,4))
legend(1, 4, c("    Setosa Petals", "    Setosa Sepals",
"Versicolor Petals", "Versicolor Sepals"),
pch = "sSvV", col = rep(c(2,4), 2))
iris3
tibble(iris)
tibble(iris)
iris_tib <- tibble(iris)
iris_tib
class(iris_tib)
is.matrix(iris_tib)
boxplot(iris$Sepal.Length)
barplot(iris$Sepal.Length)
plot(iris$Sepal.Length, iris$Petal.Length, main = "Scatterplot of Sepal Length vs. Petal Length")
plot(iris$Sepal.Length, iris$Petal.Length, main = "Scatterplot of Sepal Length vs. Petal Length")
plot(iris$Sepal.Length, iris$Petal.Length,
main = "Scatterplot of Sepal Length vs. Petal Length",
xlab = "Sepal Length (in cm)",
ylab = "Petal Length (in cm)")
model <- lm(iris$Petal.Length ~ iris$Sepal.Length)
abline(model, col = "red")
correlation
total_area <- function(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width){Sepal.Area <- Sepal.Length * Sepal.Width; Petal.Area <- Petal.Length*Petal.Width; total_area <- Sepal.Area + Petal.Area; return(total_area)}
iris %>% mutate(total_area = total_area(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width))
?filter
unique(iris$Species)
set.seed(10)
min_greater_2 <- function() {
s <- sample(1:6, 3, replace = T)
return(min(s) > 2)
}
r <- replicate(10000, min_greater_2())
mean(r)
min_greater_2 <- function() {
s <- sample(1:6, 3, replace = T)
return(min(s) > 2)
}
r <- replicate(100000, min_greater_2())
mean(r)
replicate(10000, min(sample(1:6, 3, replace = T)) > 2) |>
mean()
replicate(100000, min(sample(1:6, 3, replace = T)) > 2) |>
mean()
second_greater <- function() {
s <- sample(1:6, 2, replace = T)
s[2] > s[1]
}
mean(replicate(10000, second_greater()))
diff(c(0, 4, 10))
replicate(10000, diff(sample(1:6, 2, replace = T)) > 0) |>
mean()
sample(1:100)
x <- 1:100
is_deranged_loop <- function(){
counta <- 0
x1 <- sample(x)
for(i in seq_along(x)){
if(x1[i] == i){
counta = counta + 1
}
}
return(counta <= 0)
}
mean(replicate(10000, is_deranged_loop()))
sample(1:100)
1:100
sample(1:100) == 1:100
is_deranged <- function() {
!any(sample(1:100) == 1:100) # Think about what this does!
}
result <- replicate(10000, is_deranged())
mean(result)
running_mean <- function(k) {
mean(result[seq_len(k)])
}
running_means <- sapply(1:10000, running_mean)
head(running_means)
head(cumsum(result))
head(cumsum(result) / 1:10000)
running_means <- cumsum(result) / 1:10000
plot(1:10000, running_means, type = 'l', main = "Probability of a derangement",
xlab = "no. reps", ylab = "p")
abline(h = 1/exp(1), col = "red")
set.seed(100)
before_six <- function() {
s <- sample(1:6, 100, replace= T)
which(s == 6)[1] - 1 # Minus 1 since we do not count the roll which scored 6.
}
replicate(10000, before_six()) |> mean()
con <- "~/Documents/GitHub/python-1-billion-row-challenge/data/measurements.txt"
readLines(con, n = 1)
# readLines arguments
con <- "~/Documents/GitHub/python-1-billion-row-challenge/data/measurements.txt"
n <- 1
ok = TRUE
warn = TRUE
encoding = "unknown"
skipNul = FALSE
.Internal(readLines(con, n, ok, warn, encoding, skipNul))
# readLines arguments
con <- "~/Documents/GitHub/python-1-billion-row-challenge/data/measurements.txt"
con <- file(con, "r")
on.exit(close(con))
n <- 1
ok = TRUE
warn = TRUE
encoding = "unknown"
skipNul = FALSE
.Internal(readLines(con, n, ok, warn, encoding, skipNul))
?microbenchmark::microbenchmark
)
microbenchmark::microbenchmark(
list(readLines(path, n),
.Internal(readLines(con, n, ok, warn, encoding, skipNul)))
)
# readLines arguments
path <- "~/Documents/GitHub/python-1-billion-row-challenge/data/measurements.txt"
microbenchmark::microbenchmark(
list(readLines(path, n),
.Internal(readLines(con, n, ok, warn, encoding, skipNul)))
)
microbenchmark::microbenchmark(
list(readLines(path, n),
.Internal(readLines(con, n, ok, warn, encoding, skipNul)))
)
microbenchmark::microbenchmark(
list(vanilla = readLines(path, n),
internal = .Internal(readLines(con, n, ok, warn, encoding, skipNul)))
)
library(microbenchmark)
# Define the file path
path <- "~/Documents/GitHub/python-1-billion-row-challenge/data/measurements.txt"
# Define common parameters
n <- 1L
ok <- TRUE
warn <- TRUE
encoding <- "unknown"
skipNul <- FALSE
# Open connection
con <- file(path, "r")
# Ensure the connection is closed after benchmarking
on.exit(close(con))
# Benchmarking the two methods
benchmark_results <- microbenchmark(
vanilla = {
# Close and reopen the connection to reset it for the next read
close(con)
con <- file(path, "r")
readLines(con, n)
},
internal = {
# Close and reopen the connection to reset it for the next read
close(con)
con <- file(path, "r")
.Internal(readLines(con, n, ok, warn, encoding, skipNul))
},
times = 100  # Number of iterations
)
# Print the benchmark results
print(benchmark_results)
library(microbenchmark)
# Define the file path
path <- "~/Documents/GitHub/python-1-billion-row-challenge/data/measurements.txt"
# Define common parameters
n <- 1L
ok <- TRUE
warn <- TRUE
encoding <- "unknown"
skipNul <- FALSE
# Open connection
con <- file(path, "r")
# Ensure the connection is closed after benchmarking
on.exit(close(con))
# Benchmarking the two methods
benchmark_results <- microbenchmark(
vanilla = {
# Close and reopen the connection to reset it for the next read
close(con)
con <- file(path, "r")
readLines(con, n)
},
internal = {
# Close and reopen the connection to reset it for the next read
close(con)
con <- file(path, "r")
.Internal(readLines(con, n, ok, warn, encoding, skipNul))
},
times = 100  # Number of iterations
)
# Print the benchmark results
print(benchmark_results)
# Benchmarking the two methods
benchmark_results <- microbenchmark(
vanilla = {
# Close and reopen the connection to reset it for the next read
close(con)
con <- file(path, "r")
readLines(con, n)
},
internal = {
# Close and reopen the connection to reset it for the next read
close(con)
con <- file(path, "r")
.Internal(readLines(con, n, ok, warn, encoding, skipNul))
},
times = 1000  # Number of iterations
)
# Print the benchmark results
print(benchmark_results)
# Benchmarking the two methods
benchmark_results <- microbenchmark(
vanilla = {
# Close and reopen the connection to reset it for the next read
close(con)
con <- file(path, "r")
readLines(con, n)
},
internal = {
# Close and reopen the connection to reset it for the next read
close(con)
con <- file(path, "r")
.Internal(readLines(con, n, ok, warn, encoding, skipNul))
},
times = 100000  # Number of iterations
)
# Print the benchmark results
print(benchmark_results)
getAnywhere(readLines)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- 1L
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- 1
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- 1
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- 1
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- "1"
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- "1"
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- "1"
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- 1L
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
traceback()
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- 1L
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- 1
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- 1
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- 1L
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# path <- "example.txt"
n <- 1L
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# Test parameters
# con <- "example.txt"
n <- 1
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
# Define the file path
path <- "~/Documents/GitHub/python-1-billion-row-challenge/data/measurements.txt"
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
cat("R diagnostics:\n")
cat("con:", con, "\n")
cat("n:", n, "\n")
cat("ok:", ok, "\n")
cat("warn:", warn, "\n")
cat("encoding:", encoding, "\n")
cat("skipNul:", skipNul, "\n")
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# Test parameters
# con <- "example.txt"
n <- 1
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)
dyn.load("~/Documents/GitHub/python-1-billion-row-challenge/data/readLines.so")
readLinesC <- function(con, n, ok, warn, encoding, skipNul) {
cat("R diagnostics:\n")
cat("con:", con, "\n")
cat("n:", n, "\n")
cat("ok:", ok, "\n")
cat("warn:", warn, "\n")
cat("encoding:", encoding, "\n")
cat("skipNul:", skipNul, "\n")
.Call("readLinesC", as.character(con), as.integer(n), as.logical(ok), as.logical(warn), as.character(encoding), as.logical(skipNul))
}
# Test parameters
path <- "~/Documents/GitHub/python-1-billion-row-challenge/data/measurements.txt"
n <- 1
ok <- TRUE
warn <- TRUE
encoding <- "UTF-8"
skipNul <- FALSE
readLinesC(path, n, ok, warn, encoding, skipNul)

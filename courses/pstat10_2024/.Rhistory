text_list <- list(text1, text2, text3, text4)
titles <- c(
"How satisfied are you with the course overall?",
"How satisfied are you with your section?",
"How satisfied are you with lectures?",
"How could the instructor or the TAs improve the course?"
)
mapply(create_wordcloud, text_list, titles)
?wordcloud
# Define the function
create_wordcloud <- function(text, title) {
# Create a Corpus
corpus <- Corpus(VectorSource(text))
# Preprocess the text data
corpus <- tm_map(corpus, removeWords, c("course", "class", "code", "lecture", "professor"))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
# Create a Term-Document Matrix
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
df <- data.frame(word = names(word_freqs), freq = word_freqs)
# Generate the word cloud
set.seed(1234) # for reproducibility
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, title)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words = 100, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"),
main = "Title")
}
# Example usage
text_list <- list(text1, text2, text3, text4)
titles <- c(
"How satisfied are you with the course overall?",
"How satisfied are you with your section?",
"How satisfied are you with lectures?",
"How could the instructor or the TAs improve the course?"
)
mapply(create_wordcloud, text_list, titles)
# Define the function
create_wordcloud <- function(text, title) {
# Create a Corpus
corpus <- Corpus(VectorSource(text))
# Preprocess the text data
corpus <- tm_map(corpus, removeWords, c("course", "class", "code", "lecture", "lecture", "professor"))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
# Create a Term-Document Matrix
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
df <- data.frame(word = names(word_freqs), freq = word_freqs)
# Generate the word cloud
set.seed(1234) # for reproducibility
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, title)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words = 100, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"),
main = "Title")
}
# Example usage
text_list <- list(text1, text2, text3, text4)
titles <- c(
"How satisfied are you with the course overall?",
"How satisfied are you with your section?",
"How satisfied are you with lectures?",
"How could the instructor or the TAs improve the course?"
)
mapply(create_wordcloud, text_list, titles)
# Define the function
create_wordcloud <- function(text, title) {
# Create a Corpus
corpus <- Corpus(VectorSource(text))
# Preprocess the text data
corpus <- tm_map(corpus, removeWords, c("course", "class", "code", "lecture", "lecture", "professor"))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removeWords, c("lectur"))
# Create a Term-Document Matrix
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
df <- data.frame(word = names(word_freqs), freq = word_freqs)
# Generate the word cloud
set.seed(1234) # for reproducibility
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, title)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words = 100, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"),
main = "Title")
}
# Example usage
text_list <- list(text1, text2, text3, text4)
titles <- c(
"How satisfied are you with the course overall?",
"How satisfied are you with your section?",
"How satisfied are you with lectures?",
"How could the instructor or the TAs improve the course?"
)
mapply(create_wordcloud, text_list, titles)
# Define the function
create_wordcloud <- function(text, title) {
# Create a Corpus
corpus <- Corpus(VectorSource(text))
# Preprocess the text data
corpus <- tm_map(corpus, removeWords, c("course", "class", "code", "lecture", "lecture", "professor"))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removeWords, c("lectur", "content"))
# Create a Term-Document Matrix
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
df <- data.frame(word = names(word_freqs), freq = word_freqs)
# Generate the word cloud
set.seed(1234) # for reproducibility
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, title)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words = 100, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"),
main = "Title")
}
# Example usage
text_list <- list(text1, text2, text3, text4)
titles <- c(
"How satisfied are you with the course overall?",
"How satisfied are you with your section?",
"How satisfied are you with lectures?",
"How could the instructor or the TAs improve the course?"
)
mapply(create_wordcloud, text_list, titles)
install.packages("syuzhet")
library(syuzhet)
# Define the sentiment analysis function
perform_sentiment_analysis <- function(text) {
# Preprocess the text data
text <- tolower(text)
text <- removePunctuation(text)
text <- removeNumbers(text)
text <- removeWords(text, stopwords("english"))
text <- stripWhitespace(text)
# Perform sentiment analysis
sentiments <- get_nrc_sentiment(text)
# Summarize the sentiment scores
sentiment_scores <- colSums(sentiments)
return(sentiment_scores)
}
# Example usage
text_list <- list(text1, text2, text3, text4)
# Perform sentiment analysis on each text and print results
sentiment_results <- lapply(text_list, perform_sentiment_analysis)
names(sentiment_results) <- titles
# Print sentiment analysis results
print(sentiment_results)
lapply(sentiment_results, barplot)
lapply(sentiment_results, barplot)
lapply(sentiment_results, function(x) ggplot(aes(x=.)) + geom_bar())
lapply(sentiment_results, function(x) ggplot(aes(x=x)) + geom_bar())
lapply(sentiment_results, str)
lapply(sentiment_results, function(x) ggplot(aes(x=names(x), y = x))) + geom_bar())
# Print sentiment analysis results
print(sentiment_results)
lapply(sentiment_results, function(x) ggplot(aes(x=names(x), y = x))) + geom_bar())
# Plot sentiment analysis results
plot_sentiments <- function(sentiment_scores, title) {
df <- data.frame(sentiment = names(sentiment_scores), score = sentiment_scores)
ggplot(df, aes(x = sentiment, y = score)) +
geom_bar(stat = "identity", fill = "steelblue") +
theme_minimal() +
labs(title = title, x = "Sentiment", y = "Score") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
lapply(sentiment_results, plot_sentiments)
lapply(sentiment_results, plot_sentiments, titles)
mapply(sentiment_results, titles, plot_sentiments)
map2(sentiment_results, titles, plot_sentiments)
library(tm)
library(SnowballC)
library(wordcloud)
library(syuzhet)
# text1 <- clipr::read_clip_tbl()
# text2 <- clipr::read_clip_tbl()
# text3 <- clipr::read_clip_tbl()
# text4 <- clipr::read_clip_tbl()
# Define the function
create_wordcloud <- function(text, title) {
# Create a Corpus
corpus <- Corpus(VectorSource(text))
# Preprocess the text data
corpus <- tm_map(corpus, removeWords, c("course", "class", "code", "lecture", "lecture", "professor"))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removeWords, c("lectur", "content"))
# Create a Term-Document Matrix
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
df <- data.frame(word = names(word_freqs), freq = word_freqs)
# Generate the word cloud
set.seed(1234) # for reproducibility
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, title)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words = 100, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"),
main = "Title")
}
# Example usage
text_list <- list(text1, text2, text3, text4)
titles <- c(
"How satisfied are you with the course overall?",
"How satisfied are you with your section?",
"How satisfied are you with lectures?",
"How could the instructor or the TAs improve the course?"
)
mapply(create_wordcloud, text_list, titles)
# sentiment analysis
# Define the sentiment analysis function
perform_sentiment_analysis <- function(text) {
# Preprocess the text data
text <- tolower(text)
text <- removePunctuation(text)
text <- removeNumbers(text)
text <- removeWords(text, stopwords("english"))
text <- stripWhitespace(text)
# Perform sentiment analysis
sentiments <- get_nrc_sentiment(text)
# Summarize the sentiment scores
sentiment_scores <- colSums(sentiments)
return(sentiment_scores)
}
# Example usage
text_list <- list(text1, text2, text3, text4)
# Perform sentiment analysis on each text and print results
sentiment_results <- lapply(text_list, perform_sentiment_analysis)
names(sentiment_results) <- titles
# Print sentiment analysis results
# print(sentiment_results)
# plot sentiments
# Plot sentiment analysis results
plot_sentiments <- function(sentiment_scores, title) {
df <- data.frame(sentiment = names(sentiment_scores), score = sentiment_scores)
ggplot(df, aes(x = sentiment, y = score)) +
geom_bar(stat = "identity", fill = "steelblue") +
theme_minimal() +
labs(title = title, x = "Sentiment", y = "Score") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
map2(sentiment_results, titles, plot_sentiments)
text_list
text_list
getwd()
setwd("/Users/ingmarsturm/Documents/GitHub/essentialols.github.io/courses/pstat10_2024/")
for (i in seq_along(text_list)) {
write_csv(x = text_list[i], file = paste0(str_trunc(names(text_list[i]), 10), ".csv"))
}
for (i in seq_along(text_list)) {
write_csv(x = text_list[[i]], file = paste0(str_trunc(names(text_list[i]), 10), ".csv"))
}
for (i in seq_along(text_list)) {
print(paste0(str_trunc(names(text_list[i]), 10), ".csv"))
write_csv(x = text_list[[i]], file = paste0(str_trunc(names(text_list[i]), 10), ".csv"))
}
for (i in seq_along(text_list)) {
print(paste0(str_trunc(names(text_list[[i]]), 10), ".csv"))
write_csv(x = text_list[[i]], file = paste0(str_trunc(names(text_list[i]), 10), ".csv"))
}
for (i in seq_along(text_list)) {
print(paste0("~/Downloads/", str_trunc(names(text_list[[i]]), 10), ".csv"))
write_csv(x = text_list[[i]], file = paste0("~/Downloads/", str_trunc(names(text_list[[i]]), 10), ".csv"))
}
for (i in seq_along(text_list)) {
print(paste0("~/Downloads/", str_trunc(names(text_list[[i]]), 10), ".csv"))
write_csv(x = text_list[[i]], file = paste0("~/Downloads/", str_trunc(names(text_list[[i]]), 20), ".csv"))
}
for (i in seq_along(text_list)) {
print(paste0("~/Downloads/", str_trunc(names(text_list[[i]]), 10), ".csv"))
write_csv(x = text_list[[i]], file = paste0("~/Downloads/", str_trunc(names(text_list[[i]]), 30), ".csv"))
}
titles
write_csv(tibble(plot_titles = titles), "~/Downloads/plot_titles.csv")
map2(sentiment_results, titles, ~ plot_sentiments(.x, .y) %>% png(paste0("~/Downloads/", str_trunc(.y, 30), ".png"))
)
map2(sentiment_results, titles, ~ plot_sentiments(.x, .y))
map2(sentiment_results, titles, ~ plot_sentiments(.x, .y) %>% png(., paste0("~/Downloads/", str_trunc(.y, 30), ".png")))
map2(sentiment_results, titles, ~ plot_sentiments(.x, .y) %>% png(., filename = paste0("~/Downloads/", str_trunc(.y, 30), ".png")))
map2(sentiment_results, titles, ~ {
p <- plot_sentiments(.x, .y)
ggsave(filename = paste0("~/Downloads/", str_trunc(.y, 30), ".png"), plot = p)
})
map2(sentiment_results, titles, ~ {
p <- plot_sentiments(.x, .y)
ggsave(filename = paste0("~/Downloads/", str_trunc(.y, 40), ".png"), plot = p)
})
# Plot sentiment analysis results
plot_sentiments <- function(sentiment_scores, title) {
df <- data.frame(sentiment = names(sentiment_scores), score = sentiment_scores)
ggplot(df, aes(x = sentiment, y = score)) +
geom_bar(stat = "identity", fill = "steelblue") +
theme_minimal() +
labs(title = title, x = "Sentiment", y = "Score") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
map2(text_list, titles, ~ {
p <- create_wordcloud(.x, .y)
ggsave(filename = paste0("~/Downloads/WC_", str_trunc(.y, 40), ".png"), plot = p)
})
map2(text_list, titles, ~ {
png(filename = paste0("~/Downloads/WC_", str_trunc(.y, 40), ".png"))
create_wordcloud(.x, .y)
dev.off()
})
map2(text_list, titles, ~ {
png(filename = paste0("~/Downloads/WC_", str_trunc(.y, 40), ".png"), width = 800, height = 800)
create_wordcloud(.x, .y)
dev.off()
})
?wordcloud
map2(text_list, titles, ~ {
png(filename = paste0("~/Downloads/WC_", str_trunc(.y, 40), ".png"), width=12, height=8, res = 300)
create_wordcloud(.x, .y)
dev.off()
})
map2(text_list, titles, ~ {
png(filename = paste0("~/Downloads/WC_", str_trunc(.y, 40), ".png"), width=12, height=8,units = "in" res = 300)
map2(text_list, titles, ~ {
png(filename = paste0("~/Downloads/WC_", str_trunc(.y, 40), ".png"), width=12, height=8,units = "in", res = 300)
create_wordcloud(.x, .y)
dev.off()
})
# Define the function
create_wordcloud <- function(text, title) {
# Create a Corpus
corpus <- Corpus(VectorSource(text))
# Preprocess the text data
corpus <- tm_map(corpus, removeWords, c("course", "class", "code", "lecture", "lecture", "professor"))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removeWords, c("lectur", "content"))
# Create a Term-Document Matrix
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
df <- data.frame(word = names(word_freqs), freq = word_freqs)
# Generate the word cloud
set.seed(1234) # for reproducibility
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=15, title)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words = 100, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"),
main = "Title")
}
map2(text_list, titles, ~ {
png(filename = paste0("~/Downloads/WC_", str_trunc(.y, 40), ".png"), width=12, height=8,units = "in", res = 300)
create_wordcloud(.x, .y)
dev.off()
})
# Define the function
create_wordcloud <- function(text, title) {
# Create a Corpus
corpus <- Corpus(VectorSource(text))
# Preprocess the text data
corpus <- tm_map(corpus, removeWords, c("course", "class", "code", "lecture", "lecture", "professor"))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removeWords, c("lectur", "content"))
# Create a Term-Document Matrix
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
df <- data.frame(word = names(word_freqs), freq = word_freqs)
# Generate the word cloud
set.seed(1234) # for reproducibility
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=2, title)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words = 100, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"),
main = "Title")
}
map2(text_list, titles, ~ {
png(filename = paste0("~/Downloads/WC_", str_trunc(.y, 40), ".png"), width=12, height=8,units = "in", res = 300)
create_wordcloud(.x, .y)
dev.off()
})
# Define the function
create_wordcloud <- function(text, title) {
# Create a Corpus
corpus <- Corpus(VectorSource(text))
# Preprocess the text data
corpus <- tm_map(corpus, removeWords, c("course", "class", "code", "lecture", "lecture", "professor"))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removeWords, c("lectur", "content"))
# Create a Term-Document Matrix
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
df <- data.frame(word = names(word_freqs), freq = word_freqs)
# Generate the word cloud
set.seed(1234) # for reproducibility
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, title)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words = 100, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"),
main = "Title")
}
map2(text_list, titles, ~ {
png(filename = paste0("~/Downloads/WC_", str_trunc(.y, 40), ".png"), width=12, height=8,units = "in", res = 300)
create_wordcloud(.x, .y)
dev.off()
})
clipr::read_clip_tbl()
a <- clipr::read_clip_tbl()
a
barplot(a)
barplot(table(a))
clipr::read_clip()
a <- clipr::read_clip()
barplot(table(a))
dev.off()
barplot(table(a))
ggplot(aes((table(a))) + geom_bar()
ggplot(aes(table(a))) + geom_bar()
ggplot(aes(a)) + geom_bar()
ggplot(aes(as.data.frame(a))) + geom_bar()
as.data.frame(a) %>% ggplot(aes()) + geom_bar()
as.data.frame(a)
as.data.frame(a) %>% ggplot(aes(a)) + geom_bar()
?scale_x_discrete()
as.data.frame(a) %>% ggplot(aes(a)) + geom_bar() + scale_x_discrete(angle = 45)
as.data.frame(a) %>% ggplot(aes(a)) + geom_bar() + theme(axis.text.x = element_text(angle = 45))
ggplot(as.data.frame(a), aes(a)) +
geom_bar() +
scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
unique(a)
unique(a[-1])
ggplot(as.data.frame(a[-1]), aes(a)) +
geom_bar() +
scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(as.data.frame(a[-1]), aes(a[-1])) +
geom_bar() +
scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(as.data.frame(a[-1]), aes(a[-1])) +
geom_bar() +
scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
theme_bw() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(as.data.frame(a[-1]), aes(a[-1])) +
geom_bar() +
scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
theme_bw() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Timer too long or too short?")
write_csv(as_tibble(a[-1]), "~/Downloads/timer.csv")
